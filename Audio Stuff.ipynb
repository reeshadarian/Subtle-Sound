{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient Name: Reeshad Arian\n",
      "Capture Heart Sound? (press Enter)\n",
      "recording started\n",
      "recording stopped\n",
      "Capture Breath Sound? (press Enter)\n",
      "recording started\n",
      "recording stopped\n",
      "Capture Speech? (press Enter)\n",
      "recording started\n",
      "recording stopped\n"
     ]
    }
   ],
   "source": [
    "capture_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import webbrowser\n",
    "filename = 'database/Reeshad Arian/index.html'\n",
    "webbrowser.open('file://' + os.path.realpath(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import webbrowser\n",
    "import speech_recognition as sr\n",
    "import wave\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import  scipy.signal as signal\n",
    "from collections import Counter\n",
    "r = sr.Recognizer()\n",
    "from IPython.display import Audio\n",
    "import parselmouth\n",
    "from numpy.fft import rfft\n",
    "from numpy import argmax, mean, diff, log, nonzero\n",
    "from scipy.signal import blackmanharris, correlate\n",
    "from time import time\n",
    "import parselmouth\n",
    "from parselmouth.praat import call\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "from IPython.display import display, Markdown\n",
    "import pickle\n",
    "\n",
    "def capture_sound(sound_type, patient_name='', time=10, rate=44100):\n",
    "    patient_name = 'database/' + patient_name + '/'\n",
    "    if not os.path.exists(patient_name):\n",
    "        os.makedirs(patient_name)\n",
    "    RECORD_SECONDS = time\n",
    "    if sound_type == \"speech\":\n",
    "        WAVE_OUTPUT_FILENAME = patient_name+\"speechFile.wav\"\n",
    "        index = 2\n",
    "    elif sound_type == \"heart\":\n",
    "        WAVE_OUTPUT_FILENAME = patient_name+ \"heartFile.wav\"\n",
    "        index = 1\n",
    "    else:\n",
    "        WAVE_OUTPUT_FILENAME = patient_name+\"breathFile.wav\"\n",
    "        index = 1\n",
    "    audio = pyaudio.PyAudio()\n",
    "\n",
    "    stream = audio.open(format=pyaudio.paInt16, channels=2,\n",
    "                    rate=rate, input=True,input_device_index = index,\n",
    "                    frames_per_buffer=1024)\n",
    "    print (\"recording started\")\n",
    "    Recordframes = []\n",
    "\n",
    "    for i in range(0, int(rate / 1024 * time)):\n",
    "        data = stream.read(1024)\n",
    "        Recordframes.append(data)\n",
    "\n",
    "    print (\"recording stopped\")\n",
    "\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    audio.terminate()\n",
    "\n",
    "    waveFile = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "    waveFile.setnchannels(2)\n",
    "    waveFile.setsampwidth(audio.get_sample_size(pyaudio.paInt16))\n",
    "    waveFile.setframerate(rate)\n",
    "    waveFile.writeframes(b''.join(Recordframes))\n",
    "    waveFile.close()\n",
    "    file = open(patient_name+\"transcriptFile.txt\", \"w\")\n",
    "    if sound_type == 'speech':\n",
    "        with sr.WavFile(WAVE_OUTPUT_FILENAME) as source:              # use \"test.wav\" as the audio source\n",
    "            audio = r.record(source)                        # extract audio data from the file\n",
    "            try:\n",
    "                 file.write(r.recognize_google(audio))   # recognize speech using Google Speech Recognition\n",
    "            except:                                 # speech is unintelligible\n",
    "                print(\"Could not understand audio\")\n",
    "        file.close()\n",
    "\n",
    "def make_plots(filename, signal_type,  file_path):\n",
    "    # Read file to get buffer                                                                                               \n",
    "    ifile = wave.open(filename)\n",
    "    samples = ifile.getnframes()\n",
    "    audio = ifile.readframes(samples)\n",
    "    \n",
    "    # Convert buffer to float32 using NumPy                                                                                 \n",
    "    audio_as_np_int16 = np.frombuffer(audio, dtype=np.int16)\n",
    "    audio_as_np_float32 = audio_as_np_int16.astype(np.float32)\n",
    "    # Normalise float32 array so that values are between -1.0 and +1.0                                                      \n",
    "    max_int16 = 2**15\n",
    "    audio_normalised = audio_as_np_float32 / max_int16\n",
    "    \n",
    "    t = np.arange(0, 5*len(audio_normalised)/440320, 5/440320)\n",
    "    plt.plot(t[:len(audio_normalised)], audio_normalised)\n",
    "    plt.savefig(file_path+signal_type+\"Plot.png\")\n",
    "    plt.close()\n",
    "    s, f, _, i= plt.specgram(audio_normalised, Fs = 44100)\n",
    "    plt.savefig(file_path+signal_type+\"Spectogram.png\")\n",
    "    plt.close()\n",
    "    Audio(filename)\n",
    "\n",
    "def measurePitch(file_name, f0min = 75, f0max =500, unit = 'Hertz'):\n",
    "    voiceID = parselmouth.Sound(file_name)\n",
    "    sound = parselmouth.Sound(voiceID) # read the sound\n",
    "    pitch = call(sound, \"To Pitch\", 0.0, f0min, f0max) #create a praat pitch object\n",
    "    meanF0 = call(pitch, \"Get mean\", 0, 0, unit) # get mean pitch\n",
    "    stdevF0 = call(pitch, \"Get standard deviation\", 0 ,0, unit) # get standard deviation\n",
    "    harmonicity = call(sound, \"To Harmonicity (cc)\", 0.01, 75, 0.1, 1.0)\n",
    "    hnr = call(harmonicity, \"Get mean\", 0, 0)\n",
    "    pointProcess = call(sound, \"To PointProcess (periodic, cc)\", f0min, f0max)\n",
    "    localJitter = call(pointProcess, \"Get jitter (local)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "    localabsoluteJitter = call(pointProcess, \"Get jitter (local, absolute)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "    rapJitter = call(pointProcess, \"Get jitter (rap)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "    ppq5Jitter = call(pointProcess, \"Get jitter (ppq5)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "    ddpJitter = call(pointProcess, \"Get jitter (ddp)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "    localShimmer =  call([sound, pointProcess], \"Get shimmer (local)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    localdbShimmer = call([sound, pointProcess], \"Get shimmer (local_dB)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    apq3Shimmer = call([sound, pointProcess], \"Get shimmer (apq3)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    aqpq5Shimmer = call([sound, pointProcess], \"Get shimmer (apq5)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    apq11Shimmer =  call([sound, pointProcess], \"Get shimmer (apq11)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    ddaShimmer = call([sound, pointProcess], \"Get shimmer (dda)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "    return meanF0, stdevF0, hnr, localJitter, localabsoluteJitter, rapJitter, ppq5Jitter, ddpJitter, localShimmer, localdbShimmer, apq3Shimmer, aqpq5Shimmer, apq11Shimmer, ddaShimmer\n",
    "\n",
    "def EE(sig):\n",
    "    X = np.fft.fft(sig)\n",
    "    s = np.abs(sig)**2\n",
    "    P = s/np.sum(s)+1e-40\n",
    "    h = - np.sum(P*np.log2(P))\n",
    "    return h\n",
    "\n",
    "def zero_crossing_rate(sig):\n",
    "    sig1 = np.append(0, sig)[:-1]\n",
    "    return np.sum(np.abs(np.sign(sig)-np.sign(sig1)))/(2*len(sig))\n",
    "\n",
    "def short_time_energy(sig, N):\n",
    "    w = np.ones(N)/(2*N)\n",
    "    return signal.convolve(sig**2, w**2)\n",
    "\n",
    "def spectra_rolloff(sig, f_s, kappa=0.85):\n",
    "    _, _, X = signal.spectrogram(sig, f_s)\n",
    "    norm = X.sum(axis=0, keepdims=True)\n",
    "    norm[norm == 0] = 1\n",
    "    X = np.cumsum(X, axis=0) / norm\n",
    "    vsr = np.argmax(X >= kappa, axis=0)\n",
    "    # convert from index to Hz\n",
    "    vsr = vsr / (X.shape[0] - 1)  * f_s / 2\n",
    "    return (vsr)\n",
    "\n",
    "\n",
    "def display_data(signal_type,  patient_name):\n",
    "    res = ''\n",
    "    file_path = 'database/' + patient_name + '/'\n",
    "    filename = file_path + signal_type + 'File.wav'\n",
    "    if signal_type == 'heart':\n",
    "        title = 'Heart Data'\n",
    "    elif signal_type == 'speech':\n",
    "        title = 'Speech Data'\n",
    "    else:\n",
    "        title = 'Breathing Data'\n",
    "    ifile = wave.open(filename)\n",
    "    samples = ifile.getnframes()\n",
    "    audio = ifile.readframes(samples)\n",
    "    audio_as_np_int16 = np.frombuffer(audio, dtype=np.int16)\n",
    "    audio_as_np_float32 = audio_as_np_int16.astype(np.float32)\n",
    "    max_int16 = 2**15\n",
    "    audio_normalised = audio_as_np_float32 / max_int16\n",
    "    yy = audio_normalised\n",
    "    make_plots(filename, signal_type,  file_path)\n",
    "    if signal_type == 'speech':\n",
    "        res += 'Transcript: ' + open('database/'+patient_name+'/transcriptFile.txt').read() +'<br>'\n",
    "    meanF0, stdevF0, hnr, localJitter, localabsoluteJitter, rapJitter, ppq5Jitter, ddpJitter, localShimmer, localdbShimmer, apq3Shimmer, aqpq5Shimmer, apq11Shimmer, ddaShimmer = measurePitch(filename)\n",
    "    res += 'Mean F0: ' + str(meanF0) + '<br>'\n",
    "    res += 'Stdev F0: ' + str(stdevF0) + '<br>'\n",
    "    res += 'HNR: ' + str(hnr) + '<br>'\n",
    "    res += 'Energy Entropy: ' + str(EE(yy)) + '<br>'\n",
    "    res += 'Zero Crossing Rate: ' + str(zero_crossing_rate(yy)) + '<br>'\n",
    "    res += 'Local Jitter: ' + str(localJitter) + '<br>'\n",
    "    res += 'Local Absolute Jitter: ' + str(localabsoluteJitter) + '<br>'\n",
    "    res += 'Rap Jitter: ' + str(rapJitter) + '<br>'\n",
    "    res += 'ppq5 Jitter: ' + str(ppq5Jitter) + '<br>'\n",
    "    res += 'ddp Jitter: ' + str(ddpJitter) + '<br>'\n",
    "    res += 'Local Shimmer: ' + str(localShimmer) + '<br>'\n",
    "    res += 'Local Shimmer dB: ' + str(localdbShimmer) + '<br>'\n",
    "    res += 'apq3 Shimmer: ' + str(apq3Shimmer) + '<br>'\n",
    "    res += 'aqpq5 Shimmer: ' + str(aqpq5Shimmer) + '<br>'\n",
    "    res += 'apq11 Shimmer: ' + str(apq11Shimmer) + '<br>'\n",
    "    res += 'dda Shimmer: ' + str(ddaShimmer) + '<br>'\n",
    "    plt.plot(short_time_energy(yy, 2000))\n",
    "    plt.savefig(file_path+signal_type+'shortEnergy.png')\n",
    "    plt.close()\n",
    "    return res\n",
    "\n",
    "def capture_data(): \n",
    "    patient_name = input('Patient Name: ') \n",
    "    input('Capture Heart Sound? (press Enter)')\n",
    "    capture_sound('heart', patient_name=patient_name, time=5)\n",
    "    \n",
    "    input('Capture Breath Sound? (press Enter)')\n",
    "    capture_sound('breath', patient_name=patient_name, time=5)\n",
    "    \n",
    "    input('Capture Speech? (press Enter)')\n",
    "    capture_sound('speech', patient_name=patient_name)\n",
    "    \n",
    "    heartStats = display_data('heart', patient_name)\n",
    "    breathStats = display_data('breath', patient_name)\n",
    "    speechStats = display_data('speech', patient_name)\n",
    "    s = \"\"\"window.onload = function(){\n",
    "        document.getElementById('patientNameTitle').innerHTML = patientName + ' Report';\n",
    "        document.getElementById('reportTitle').innerHTML = patientName + ' Report';\n",
    "        document.getElementById('heartStats').innerHTML = heartStats;\n",
    "        document.getElementById('breathStats').innerHTML = breathStats;\n",
    "        document.getElementById('speechStats').innerHTML = speechStats;\n",
    "    }\"\"\"\n",
    "    contents = \"var patientName = '\" + patient_name + \"';\\n var heartStats = '\" + heartStats + \"';\\n\"\n",
    "    contents += \"var breathStats = '\" + breathStats + \"';\\n\"\n",
    "    contents += \"var speechStats = '\" + speechStats + \"';\\n\" + s\n",
    "    outfile = open('database/'+patient_name+'/control.js', 'w')\n",
    "    outfile.write(contents);\n",
    "    outfile.close()\n",
    "    s = \"\"\"<!DOCTYPE html>\n",
    "    <head><title id='patientNameTitle'></title></head>\n",
    "    <body>\n",
    "        <h1 id='reportTitle'></h1>\n",
    "        <h2>Heart Sound Report</h2>\n",
    "        <img src=\"./heartPlot.png\" alt=\"Heart data plot\" id=\"heartPlot\">\n",
    "        <img src=\"./heartSpectogram.png\" alt=\"Heart Spectogram\" id=\"heartSpectogram\">\n",
    "        <img src=\"./heartshortEnergy.png\" alt=\"Heart Short Energy\" id=\"heartShortEnergy\">\n",
    "        <audio controls>\n",
    "            <source src=\"./heartFile.wav\" type=\"audio/wav\" id=\"heartAudio\">\n",
    "            Your browser does not support the audio element.\n",
    "        </audio>\n",
    "        <p id='heartStats'></p>\n",
    "        <h2>Breath Sound Report</h2>\n",
    "        <img src=\"./breathPlot.png\" alt=\"Breath data plot\" id=\"breathPlot\">\n",
    "        <img src=\"./breathSpectogram.png\" alt=\"Breath Spectogram\" id=\"breathSpectogram\">\n",
    "        <img src=\"./breathshortEnergy.png\" alt=\"Breath Short Energy\" id=\"breathShortEnergy\">\n",
    "        <audio controls>\n",
    "            <source src=\"./breathFile.wav\" type=\"audio/wav\" id=\"breathAudio\">\n",
    "            Your browser does not support the audio element.\n",
    "        </audio>\n",
    "        <p id='breathStats'></p>\n",
    "        <h2>Speech Sound Report</h2>\n",
    "        <img src=\"./speechPlot.png\" alt=\"Speech data plot\" id=\"speechPlot\">\n",
    "        <img src=\"./speechSpectogram.png\" alt=\"Speech Spectogram\" id=\"speechSpectogram\">\n",
    "        <img src=\"./speechshortEnergy.png\" alt=\"Speech Short Energy\" id=\"speechShortEnergy\">\n",
    "        <audio controls>\n",
    "            <source src=\"./speechFile.wav\" type=\"audio/wav\" id=\"speechAudio\">\n",
    "            Your browser does not support the audio element.\n",
    "        </audio>\n",
    "        <p id='speechStats'></p>\n",
    "        <script src=\"control.js\"></script>\n",
    "    </body>\"\"\"\n",
    "    outfile = open('database/'+patient_name+'/index.html', 'w')\n",
    "    outfile.write(s)\n",
    "    outfile.close()\n",
    "    webbrowser.open('file://' + os.path.realpath('database/'+patient_name+'/index.html'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 1, 0, 1],\n",
       "       [1, 3, 1, 1],\n",
       "       [0, 1, 2, 1],\n",
       "       [1, 1, 1, 3]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = np.array([[1, 0, 0, 1, 0], [1, 1, 0, 0, 1], [0, 1, 1, 0, 0], [0, 0, 1, 1, 1]])\n",
    "B@B.T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
